{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nantmoe-theingi/airbnb-nz-deception-sentiment/blob/main/notebooks/06_run_airbnb_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new .py file and open it for editing\n",
        "file_name = \"run_airbnb_inference.py\"\n",
        "with open(file_name, \"w\") as f:\n",
        "    f.write(\"\")  # empty file created\n",
        "print(f\"{file_name} created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQfOLKPqSJr-",
        "outputId": "eee52ad6-45f4-436b-f544-c93a113db07d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run_airbnb_inference.py created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_airbnb_inference.py \\\n",
        "  --input_parquet data/airbnb_reviews_cleaned.parquet \\\n",
        "  --output_path outputs/airbnb_predictions.parquet \\\n",
        "  --deception_model_dir artifacts/distilbert_deception_sweep/best_model \\\n",
        "  --sentiment_model_dir artifacts/distilbert_sentiment_sweep/best_model"
      ],
      "metadata": {
        "id": "lMRjzLGC5wy4",
        "outputId": "d1e57402-aa7c-4670-9168-717ae7160508",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-30 03:47:43.374668: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761796063.394799    2321 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761796063.401123    2321 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761796063.417017    2321 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761796063.417057    2321 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761796063.417068    2321 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761796063.417073    2321 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-30 03:47:43.421791: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[DONE] Wrote 1,533,422 rows to outputs/airbnb_predictions.parquet in 3491.4s (439 rows/s).\n",
            "[VALIDATION] Output OK; predictions present and non-null.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_airbnb_inference.py \\\n",
        "  --input_parquet data/airbnb_reviews_cleaned.parquet \\\n",
        "  --output_path outputs/airbnb_predictions_partition/ \\\n",
        "  --partition_by year month \\\n",
        "  --deception_model_dir artifacts/distilbert_deception_sweep/best_model \\\n",
        "  --sentiment_model_dir artifacts/distilbert_sentiment_sweep/best_model"
      ],
      "metadata": {
        "id": "QKC8cbu-5mej",
        "outputId": "8c32e7bc-5897-4384-c67b-6e41ac973dae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-28 23:18:29.928352: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761693509.948310   16327 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761693509.954317   16327 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761693509.970534   16327 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761693509.970559   16327 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761693509.970563   16327 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761693509.970566   16327 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-28 23:18:29.975367: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[DONE] Wrote 1,533,422 rows to outputs/airbnb_predictions_partition/ in 3049.7s (503 rows/s).\n",
            "[VALIDATION WARNING] Skipped or partial validation due to: 'pyarrow._dataset.FileSystemDataset' object has no attribute 'scan'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_parquet(\"outputs/airbnb_predictions.parquet\")\n",
        "print(df.shape)\n",
        "print(df.columns.tolist()[-12:])   # show prediction columns\n",
        "print(df[[\"sent_pred\", \"deception_pred\"]].value_counts().head())"
      ],
      "metadata": {
        "id": "F0fycImJ6c5r",
        "outputId": "ee72ca58-74c8-4058-da97-36223513e4c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1533422, 27)\n",
            "['deception_logit_0', 'deception_logit_1', 'sent_logit_0', 'sent_logit_1', 'sent_logit_2', 'deception_prob_label_0', 'deception_prob_label_1', 'sent_prob_negative', 'sent_prob_neutral', 'sent_prob_positive', 'deception_pred', 'sent_pred']\n",
            "sent_pred  deception_pred\n",
            "2          0                 1197587\n",
            "           1                  269337\n",
            "1          0                   43173\n",
            "0          0                   22383\n",
            "1          1                     787\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "id": "-IrbwIqOh2QK",
        "outputId": "b23212b5-7392-41bd-9ab1-5eac86b584b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['review_id', 'listing_id', 'date', 'text', 'price_num', 'property_type', 'room_type', 'host_is_superhost', 'neighbourhood', 'region_name', 'region_parent_name', 'region_parent_parent_name', 'region', 'year', 'month', 'deception_logit_0', 'deception_logit_1', 'sent_logit_0', 'sent_logit_1', 'sent_logit_2', 'deception_prob_label_0', 'deception_prob_label_1', 'sent_prob_negative', 'sent_prob_neutral', 'sent_prob_positive', 'deception_pred', 'sent_pred']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the datasets\n",
        "reviews = pd.read_csv(\"data/airbnb_nz_reviews.csv\")\n",
        "listings = pd.read_csv(\"data/airbnb_nz_listings.csv\")\n",
        "preds = pd.read_parquet(\"outputs/airbnb_predictions.parquet\")\n",
        "\n",
        "RUNTIME_SECONDS = 3491.4\n",
        "\n",
        "# Canonicalise keys/dates exactly for the columns you specified ---\n",
        "def canon_id(s: pd.Series) -> pd.Series:\n",
        "    return s.astype(\"string\").str.strip().str.replace(r\"\\.0$\", \"\", regex=True)\n",
        "\n",
        "for df, cols in [\n",
        "    (reviews,  [\"id\", \"reviewer_id\"]),\n",
        "    (preds,    [\"review_id\", \"listing_id\", \"date\"]),\n",
        "    (listings, [\"id\"]),\n",
        "]:\n",
        "    for c in cols:\n",
        "        if c in df.columns:\n",
        "            if c == \"date\":\n",
        "                df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
        "            else:\n",
        "                df[c] = canon_id(df[c])\n",
        "\n",
        "# Use PREDICTIONS as the anchor\n",
        "# Join preds -> reviews ONLY to fetch reviewer_id for predicted rows\n",
        "preds_with_reviewer = preds.merge(\n",
        "    reviews[[\"id\", \"reviewer_id\"]],\n",
        "    how=\"left\",\n",
        "    left_on=\"review_id\",\n",
        "    right_on=\"id\"\n",
        ")\n",
        "\n",
        "# quick sanity checks\n",
        "predictions_generated = len(preds)  # count of rows that actually have predictions\n",
        "missing_reviewer_ids = preds_with_reviewer[\"reviewer_id\"].isna().sum()\n",
        "\n",
        "\n",
        "\n",
        "# Compute metrics restricted to the prediction subset\n",
        "total_reviews = int(\"1533422\")  # full cleaned corpus (for coverage denominator)\n",
        "coverage = predictions_generated / total_reviews if total_reviews else np.nan\n",
        "\n",
        "# Unique listings seen in predictions\n",
        "unique_listings_pred = preds[\"listing_id\"].nunique()\n",
        "\n",
        "# Unique reviewers *whose reviews appear in preds*\n",
        "unique_reviewers_pred = preds_with_reviewer[\"reviewer_id\"].nunique()\n",
        "\n",
        "# Date span derived from preds['date'] (NOT from all reviews)\n",
        "if \"date\" in preds.columns and preds[\"date\"].notna().any():\n",
        "    date_lo, date_hi = preds[\"date\"].min(), preds[\"date\"].max()\n",
        "    date_span_txt = f\"{date_lo:%b~%Y}--{date_hi:%b~%Y}\"\n",
        "else:\n",
        "    date_span_txt = \"N/A\"\n",
        "\n",
        "throughput = predictions_generated / RUNTIME_SECONDS if RUNTIME_SECONDS else np.nan\n",
        "\n",
        "# Build summary (values reflect prediction-anchored counts where applicable)\n",
        "def fmt_int(n): return f\"{int(n):,}\".replace(\",\", \"{,}\")\n",
        "def fmt_pct(x): return f\"{x*100:.2f}\\\\%\"\n",
        "\n",
        "summary_rows = [\n",
        "    (\"Total reviews processed\", \"Reviews in the cleaned Airbnb corpus\", fmt_int(total_reviews)),\n",
        "    (\"Predictions generated\",   \"Reviews with valid DistilBERT outputs\", fmt_int(predictions_generated)),\n",
        "    (\"Prediction coverage\",     \"Share of total reviews with predictions\", fmt_pct(coverage) if pd.notna(coverage) else \"N/A\"),\n",
        "    (\"Date span\",               \"Review period covered by predictions\", date_span_txt),\n",
        "    (\"Unique listings\",         \"Distinct listings represented in predictions\", fmt_int(unique_listings_pred)),\n",
        "    (\"Unique reviewers\",        \"Distinct reviewers represented in predictions\", fmt_int(unique_reviewers_pred)),\n",
        "    (\"Runtime (s)\",             \"Total inference execution time\", f\"{RUNTIME_SECONDS:,.1f}\".replace(\",\", \"{,}\")),\n",
        "    (\"Processing throughput\",   \"Reviews processed per second\", f\"{throughput:.0f}\" if pd.notna(throughput) else \"(insert value)\"),\n",
        "]\n",
        "\n",
        "df_summary = pd.DataFrame(summary_rows, columns=[\"Metric\", \"Description\", \"Value\"])\n",
        "print(df_summary)\n",
        "\n",
        "# Save CSV\n",
        "csv_path = \"figures/airbnb_inference_integrity_summary.csv\"\n",
        "df_summary.to_csv(csv_path, index=False)\n",
        "print(f\"Saved: {csv_path}\")\n",
        "print(f\"Missing reviewer_id after join: {missing_reviewer_ids:,}\")\n"
      ],
      "metadata": {
        "id": "Q0uElj2DgKRc",
        "outputId": "d43352a9-223c-431c-b166-15fcd4666a1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Metric                                    Description  \\\n",
            "0  Total reviews processed           Reviews in the cleaned Airbnb corpus   \n",
            "1    Predictions generated          Reviews with valid DistilBERT outputs   \n",
            "2      Prediction coverage        Share of total reviews with predictions   \n",
            "3                Date span           Review period covered by predictions   \n",
            "4          Unique listings   Distinct listings represented in predictions   \n",
            "5         Unique reviewers  Distinct reviewers represented in predictions   \n",
            "6              Runtime (s)                 Total inference execution time   \n",
            "7    Processing throughput                   Reviews processed per second   \n",
            "\n",
            "                Value  \n",
            "0       1{,}533{,}422  \n",
            "1       1{,}533{,}422  \n",
            "2            100.00\\%  \n",
            "3  Oct~2022--Aug~2025  \n",
            "4            39{,}017  \n",
            "5           758{,}710  \n",
            "6           3{,}491.4  \n",
            "7                 439  \n",
            "Saved: figures/airbnb_inference_integrity_summary.csv\n",
            "Missing reviewer_id after join: 0\n"
          ]
        }
      ]
    }
  ]
}