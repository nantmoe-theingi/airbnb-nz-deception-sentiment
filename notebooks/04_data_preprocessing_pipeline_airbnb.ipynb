{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP8VZP5kqgw94m9ZWrkAqM/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nantmoe-theingi/airbnb-nz-deception-sentiment/blob/main/notebooks/04_predict_airbnb_reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.makedirs(PROJECT_DRIVE_DIR, exist_ok=True)\n",
        "print(\"Drive project folder:\", PROJECT_DRIVE_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrVdNVyf5X76",
        "outputId": "ecefafee-11fb-4207-d235-e7f75dd10fc5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive project folder: /content/drive/MyDrive/Colab Notebooks/airbnb_nz_deception_sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Colab\\ Notebooks/airbnb_nz_deception_sentiment"
      ],
      "metadata": {
        "id": "Hv7GzK2m5lnW",
        "outputId": "bf2f192a-fede-4fdf-c5f8-9c4cdb236de7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/airbnb_nz_deception_sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: DATA INTAKE & SCHEMA AUDIT\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "REVIEWS_CSV  = \"data/airbnb_nz_reviews.csv\"\n",
        "LISTINGS_CSV = \"data/airbnb_nz_listings.csv\"\n",
        "\n",
        "# 1) Load the dataset both as strings\n",
        "reviews  = pd.read_csv(REVIEWS_CSV, dtype=str, low_memory=False)\n",
        "listings = pd.read_csv(LISTINGS_CSV, dtype=str, low_memory=False)\n",
        "\n",
        "print(\"Loaded.\")\n",
        "print(\"reviews shape:\", reviews.shape)\n",
        "print(\"listings shape:\", listings.shape)"
      ],
      "metadata": {
        "id": "H6jbKnfH41we",
        "outputId": "6674f2d2-0c65-45a0-f49a-656b266a41eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded.\n",
            "reviews shape: (2951093, 6)\n",
            "listings shape: (46645, 85)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Show column sets\n",
        "print(\"\\nreviews columns:\", list(reviews.columns))\n",
        "print(\"\\nlistings columns:\", list(listings.columns))"
      ],
      "metadata": {
        "id": "wP8SxpM78fqd",
        "outputId": "c74db2fa-cc4c-4a7a-dfe7-c4e02ed74e6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "reviews columns: ['listing_id', 'id', 'date', 'reviewer_id', 'reviewer_name', 'comments']\n",
            "\n",
            "listings columns: ['id', 'listing_url', 'scrape_id', 'last_searched', 'last_scraped', 'source', 'name', 'description', 'neighborhood_overview', 'picture_url', 'host_id', 'host_url', 'host_name', 'host_since', 'host_location', 'host_about', 'host_response_time', 'host_response_rate', 'host_acceptance_rate', 'host_is_superhost', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', 'host_listings_count', 'host_total_listings_count', 'host_verifications', 'host_has_profile_pic', 'host_identity_verified', 'neighbourhood', 'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms', 'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability', 'availability_30', 'availability_60', 'availability_90', 'availability_365', 'calendar_last_scraped', 'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d', 'availability_eoy', 'number_of_reviews_ly', 'estimated_occupancy_l365d', 'estimated_revenue_l365d', 'first_review', 'last_review', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'requires_license', 'license', 'instant_bookable', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms', 'region_id', 'region_name', 'region_parent_id', 'region_parent_name', 'region_parent_parent_id', 'region_parent_parent_name', 'reviews_per_month']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Basic integrity checks on key columns\n",
        "must_have_reviews = [\"listing_id\",\"id\",\"date\",\"comments\"]\n",
        "missing_cols_r = [c for c in must_have_reviews if c not in reviews.columns]\n",
        "print(\"\\nMissing essential review columns:\", missing_cols_r)\n",
        "\n",
        "must_have_listings = [\"id\",\"listing_url\",\"price\",\"property_type\",\"room_type\"]\n",
        "missing_cols_l = [c for c in must_have_listings if c not in listings.columns]\n",
        "print(\"Missing essential listing columns:\", missing_cols_l)"
      ],
      "metadata": {
        "id": "6LBgi_zx8wlt",
        "outputId": "99700744-7be5-47b3-e060-caf62be04e15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing essential review columns: []\n",
            "Missing essential listing columns: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Quick data quality snapshots\n",
        "# reviews\n",
        "r_nonempty_text = reviews[\"comments\"].notna().sum() if \"comments\" in reviews else np.nan\n",
        "r_min_date = pd.to_datetime(reviews[\"date\"], errors=\"coerce\", dayfirst=True).min()\n",
        "r_max_date = pd.to_datetime(reviews[\"date\"], errors=\"coerce\", dayfirst=True).max()\n",
        "r_unique_listings = reviews[\"listing_id\"].nunique() if \"listing_id\" in reviews else np.nan\n",
        "\n",
        "print(\"\\n--- Reviews snapshot ---\")\n",
        "print(\"Total reviews:\", len(reviews))\n",
        "print(\"Reviews with non-empty 'comments':\", r_nonempty_text)\n",
        "print(\"Unique listings referenced:\", r_unique_listings)\n",
        "print(\"Date range:\", r_min_date, \"to\", r_max_date)\n",
        "\n",
        "# listings\n",
        "l_unique_ids = listings[\"id\"].nunique() if \"id\" in listings else np.nan\n",
        "print(\"\\n--- Listings snapshot ---\")\n",
        "print(\"Total listings:\", len(listings))\n",
        "print(\"Unique listing ids:\", l_unique_ids)"
      ],
      "metadata": {
        "id": "UCaQmJ8H88I4",
        "outputId": "5fa9601a-cd68-40d1-bb99-4b94491cfa43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Reviews snapshot ---\n",
            "Total reviews: 2951093\n",
            "Reviews with non-empty 'comments': 2950839\n",
            "Unique listings referenced: 41597\n",
            "Date range: 2011-03-05 00:00:00 to 2025-12-07 00:00:00\n",
            "\n",
            "--- Listings snapshot ---\n",
            "Total listings: 46645\n",
            "Unique listing ids: 46645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Null rates on a few critical fields\n",
        "def null_rate(s):\n",
        "    return float(s.isna().mean()*100)\n",
        "\n",
        "summary_nulls = {}\n",
        "for col in [\"listing_id\",\"id\",\"date\",\"comments\",\"reviewer_id\",\"reviewer_name\"]:\n",
        "    if col in reviews:\n",
        "        summary_nulls[f\"reviews.{col}\"] = round(null_rate(reviews[col]), 2)\n",
        "for col in [\"id\",\"price\",\"property_type\",\"room_type\",\"latitude\",\"longitude\",\n",
        "            \"host_is_superhost\",\"host_acceptance_rate\",\"host_response_rate\",\"amenities\"]:\n",
        "    if col in listings:\n",
        "        summary_nulls[f\"listings.{col}\"] = round(null_rate(listings[col]), 2)\n",
        "\n",
        "print(\"\\n--- Null percentage (selected columns) ---\")\n",
        "for k,v in summary_nulls.items():\n",
        "    print(f\"{k}: {v}%\")"
      ],
      "metadata": {
        "id": "wLs3I0Cx9MsM",
        "outputId": "8d21c381-06e5-4436-8a31-8efd4db063ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Null percentage (selected columns) ---\n",
            "reviews.listing_id: 0.0%\n",
            "reviews.id: 0.0%\n",
            "reviews.date: 0.0%\n",
            "reviews.comments: 0.01%\n",
            "reviews.reviewer_id: 0.0%\n",
            "reviews.reviewer_name: 0.0%\n",
            "listings.id: 0.0%\n",
            "listings.price: 4.29%\n",
            "listings.property_type: 0.0%\n",
            "listings.room_type: 0.0%\n",
            "listings.latitude: 0.0%\n",
            "listings.longitude: 0.0%\n",
            "listings.host_is_superhost: 2.04%\n",
            "listings.host_acceptance_rate: 5.7%\n",
            "listings.host_response_rate: 14.98%\n",
            "listings.amenities: 0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Preview a few rows that can cause issues\n",
        "print(\"\\nreviews.head():\")\n",
        "print(reviews.head(5).to_string(index=False)[:1200])\n",
        "print(\"\\nlistings.head():\")\n",
        "print(listings.head(5).to_string(index=False)[:1200])"
      ],
      "metadata": {
        "id": "DJBEnRBU9Vus",
        "outputId": "ca68439a-3e8a-47c9-b0ea-65ceeb390758",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "reviews.head():\n",
            "listing_id        id       date reviewer_id reviewer_name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     comments\n",
            "     46071 506601469 2019-08-10   124689447          Mari                                                                                                                                                                                                                                                                                                                                                                                                                        Donna's place was very cozy! We liked it a lot, location was good and everything worked well in the house. Thank you!\n",
            "     46071 590538377 2020-01-08   \n",
            "\n",
            "listings.head():\n",
            "                 id                                      listing_url      scrape_id last_searched last_scraped         source                    name                                                                                                                                                                                                                                                                                                        description neighborhood_overview                                                                                                                                              picture_url   host_id                                    host_url host_name host_since        host_location                                                                                                                                                                                                                 host_about host_response_time host_response_rate host_acceptance_rate host_is_superhost                                                                                                                  host_thumbnail_url                                             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Check for duplicates\n",
        "dup_reviews = reviews['id'].duplicated().sum()\n",
        "dup_listings = listings['id'].duplicated().sum()\n",
        "\n",
        "print(f\"Duplicate review IDs: {dup_reviews} ({dup_reviews / len(reviews) * 100:.4f}%)\")\n",
        "print(f\"Duplicate listing IDs: {dup_listings} ({dup_listings / len(listings) * 100:.4f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlMcYqtUOZmW",
        "outputId": "0dbcd23f-6034-41bf-ef2e-ae3a1eb750ff"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate review IDs: 0 (0.0000%)\n",
            "Duplicate listing IDs: 0 (0.0000%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) Cross-reference consistency\n",
        "linked_ratio = reviews['listing_id'].isin(listings['id']).mean() * 100\n",
        "print(f\"Listing–review linkage consistency: {linked_ratio:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeLD6QbjOyrf",
        "outputId": "26489713-44a0-4da4-9cc8-41c815164917"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing–review linkage consistency: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_hN7vo3fr8L",
        "outputId": "fa4c3c92-d880-44b4-85b5-c6d5a64005f1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.12/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langdetect import detect, DetectorFactory\n",
        "DetectorFactory.seed = 42\n",
        "\n",
        "sample = reviews['comments'].dropna().sample(500, random_state=42)\n",
        "non_english = sum(detect(c) != 'en' for c in sample)\n",
        "print(f\"Non-English rate (sampled): {non_english / len(sample) * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdyMWXKXO7tz",
        "outputId": "78a8af1a-6931-44ea-c0e4-da10bfd4d2c9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-English rate (sampled): 5.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10) Schema validation\n",
        "required_reviews_cols = [\"listing_id\", \"id\", \"date\", \"reviewer_id\", \"reviewer_name\", \"comments\"]\n",
        "required_listings_cols = [\"id\", \"price\", \"property_type\", \"room_type\", \"host_is_superhost\", \"neighbourhood\", \"region_name\", \"region_parent_name\", \"region_parent_parent_name\" ]\n",
        "\n",
        "missing_reviews = [c for c in required_reviews_cols if c not in reviews.columns]\n",
        "missing_listings = [c for c in required_listings_cols if c not in listings.columns]\n",
        "\n",
        "print(\"Missing in reviews:\", missing_reviews)\n",
        "print(\"Missing in listings:\", missing_listings)\n",
        "\n",
        "# 11) Select key columns for analysis\n",
        "reviews_df = reviews[required_reviews_cols].copy()\n",
        "listings_df = listings[required_listings_cols].copy()\n",
        "\n",
        "print(\"Reviews columns selected:\", list(reviews_df.columns))\n",
        "print(\"Listings columns selected:\", list(listings_df.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKlGo6Z8Pb1P",
        "outputId": "7b233656-1717-4275-afb9-9666e2135446"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing in reviews: []\n",
            "Missing in listings: []\n",
            "Reviews columns selected: ['listing_id', 'id', 'date', 'reviewer_id', 'reviewer_name', 'comments']\n",
            "Listings columns selected: ['listing_id', 'id', 'date', 'reviewer_id', 'reviewer_name', 'comments']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: DATA CLEANING & FILTERING (with full English filtering)\n",
        "import pandas as pd\n",
        "import re\n",
        "from langdetect import detect, DetectorFactory\n",
        "\n",
        "DetectorFactory.seed = 42  # ensure reproducibility\n",
        "\n",
        "# Helper functions\n",
        "def normalize_whitespace(s):\n",
        "    \"\"\"Trim, collapse whitespace, and remove zero-width chars.\"\"\"\n",
        "    zws = r'[\\u200B-\\u200D\\uFEFF]'\n",
        "    s = s.astype(str).str.replace(zws, '', regex=True)\n",
        "    return s.str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n",
        "print(\"STEP 2: DATA CLEANING & FILTERING\")\n",
        "\n",
        "# Normalize key columns\n",
        "for c in [\"listing_id\",\"id\",\"date\",\"reviewer_id\",\"reviewer_name\",\"comments\"]:\n",
        "    reviews_df[c] = normalize_whitespace(reviews_df[c])\n",
        "print(\"Normalized whitespace and removed control characters from key columns.\")\n",
        "\n",
        "# Drop rows with missing essential fields\n",
        "essential = [\"listing_id\",\"id\",\"date\",\"comments\"]\n",
        "before = len(reviews_df)\n",
        "missing_mask = reviews_df[essential].isna().any(axis=1) | (reviews_df[essential] == \"\").any(axis=1)\n",
        "removed_missing = missing_mask.sum()\n",
        "reviews_df = reviews_df.loc[~missing_mask].copy()\n",
        "print(f\"[Missing Values] Removed {removed_missing:,} rows → {len(reviews_df):,} remain.\")\n",
        "\n",
        "# Remove duplicate review IDs\n",
        "dup_count = reviews_df[\"id\"].duplicated(keep=\"first\").sum()\n",
        "reviews_df = reviews_df.drop_duplicates(subset=[\"id\"], keep=\"first\").copy()\n",
        "print(f\"[Duplicates] Removed {dup_count:,} duplicate review IDs → {len(reviews_df):,} remain.\")"
      ],
      "metadata": {
        "id": "I_ZJ7PkXlUl7",
        "outputId": "89fb82fc-72f9-4d37-bcb8-4e8d82655da4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 2: DATA CLEANING & FILTERING\n",
            "Normalized whitespace and removed control characters from key columns.\n",
            "[Missing Values] Removed 0 rows → 2,951,093 remain.\n",
            "[Duplicates] Removed 0 duplicate review IDs → 2,951,093 remain.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_symbol_only(text):\n",
        "    \"\"\"Return True if text has no alphabetic characters (only emojis/symbols).\"\"\"\n",
        "    if not isinstance(text, str) or text.strip() == \"\":\n",
        "        return True\n",
        "    # Use a regex pattern compatible with Python's re module\n",
        "    return not bool(re.search(r'[^\\W\\d_]', text))\n",
        "\n",
        "# Remove blank / symbol-only comments\n",
        "symbol_only_mask = reviews_df[\"comments\"].apply(is_symbol_only)\n",
        "removed_symbols = symbol_only_mask.sum()\n",
        "reviews_df = reviews_df.loc[~symbol_only_mask].copy()\n",
        "print(f\"[Symbol-only Comments] Removed {removed_symbols:,} rows → {len(reviews_df):,} remain.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npJmHLbak_uE",
        "outputId": "4d2e023e-3ee0-4e24-b64c-b0e9829de604"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Symbol-only Comments] Removed 5,794 rows → 2,945,299 remain.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect and remove non-English reviews\n",
        "import math\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from langdetect import detect, DetectorFactory\n",
        "DetectorFactory.seed = 42\n",
        "\n",
        "def detect_language_safe(text):\n",
        "    try:\n",
        "        lang = detect(text)\n",
        "        return lang if lang else \"other\"\n",
        "    except Exception:\n",
        "        return \"other\"\n",
        "\n",
        "def detect_language_in_chunk(df_chunk):\n",
        "    return df_chunk[\"comments\"].apply(detect_language_safe)\n",
        "\n",
        "# configure chunking\n",
        "N = len(reviews_df)\n",
        "chunksize = 200_000\n",
        "num_chunks = math.ceil(N / chunksize)\n",
        "\n",
        "langs = []\n",
        "print(f\"Running language detection in {num_chunks} chunk(s) of ~{chunksize:,} rows...\")\n",
        "\n",
        "for i in tqdm(range(num_chunks), desc=\"Chunks\"):\n",
        "    start = i * chunksize\n",
        "    stop  = min((i + 1) * chunksize, N)\n",
        "    chunk = reviews_df.iloc[start:stop].copy()\n",
        "    langs.append(detect_language_in_chunk(chunk))\n",
        "\n",
        "# concatenate detected languages\n",
        "reviews_df[\"lang\"] = pd.concat(langs, axis=0).reset_index(drop=True)\n",
        "\n",
        "# sanity check alignment\n",
        "assert len(reviews_df[\"lang\"]) == len(reviews_df), \"Length mismatch after chunking!\"\n",
        "\n",
        "# distribution + filter\n",
        "lang_pct = reviews_df[\"lang\"].value_counts(normalize=True).mul(100).round(2)\n",
        "print(\"Language distribution (%):\")\n",
        "print(lang_pct.to_string())\n",
        "\n",
        "non_en_removed = (reviews_df[\"lang\"] != \"en\").sum()\n",
        "reviews_df = reviews_df.loc[reviews_df[\"lang\"] == \"en\"].drop(columns=[\"lang\"]).copy()\n",
        "print(f\"[Language Filter] Removed {non_en_removed:,} non-English reviews → {len(reviews_df):,} remain.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz3jra1niDd6",
        "outputId": "f526d4dc-dc8b-49e2-f0a5-b7935e2ebe32"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running language detection in 15 chunk(s) of ~200,000 rows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Chunks: 100%|██████████| 15/15 [2:38:38<00:00, 634.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language distribution (%):\n",
            "lang\n",
            "en       93.11\n",
            "zh-cn     1.78\n",
            "de        1.25\n",
            "fr        1.14\n",
            "ko        0.59\n",
            "ro        0.32\n",
            "nl        0.24\n",
            "af        0.21\n",
            "es        0.19\n",
            "zh-tw     0.16\n",
            "so        0.15\n",
            "ja        0.13\n",
            "it        0.09\n",
            "ca        0.08\n",
            "tl        0.07\n",
            "cs        0.06\n",
            "pl        0.05\n",
            "no        0.04\n",
            "da        0.04\n",
            "pt        0.04\n",
            "sv        0.03\n",
            "hu        0.03\n",
            "cy        0.03\n",
            "sw        0.02\n",
            "id        0.02\n",
            "hr        0.02\n",
            "tr        0.01\n",
            "vi        0.01\n",
            "fi        0.01\n",
            "et        0.01\n",
            "he        0.01\n",
            "ru        0.01\n",
            "sl        0.01\n",
            "sk        0.01\n",
            "th        0.01\n",
            "lv        0.00\n",
            "lt        0.00\n",
            "ar        0.00\n",
            "sq        0.00\n",
            "other     0.00\n",
            "el        0.00\n",
            "uk        0.00\n",
            "bg        0.00\n",
            "fa        0.00\n",
            "[Language Filter] Removed 208,316 non-English reviews → 2,736,983 remain.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lang_summary_path = \"figures/language_distribution_summary.csv\"\n",
        "lang_pct.to_csv(lang_summary_path, header=[\"Percentage\"])\n",
        "print(f\"[Saved] Language distribution summary saved to: {lang_summary_path}\")"
      ],
      "metadata": {
        "id": "gSb9AN94Edrv",
        "outputId": "72a3eae8-bbc0-45e9-9662-39ce60acfd33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Saved] Language distribution summary saved to: figures/language_distribution_summary.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate comments\n",
        "dup_comments = reviews_df[\"comments\"].duplicated(keep=\"first\").sum()\n",
        "reviews_df_step2_comments = reviews_df.drop_duplicates(subset=[\"comments\"], keep=\"first\").copy()\n",
        "print(f\"[Duplicate Comments] Removed {dup_comments:,} identical comment texts → {len(reviews_df_step2_comments):,} remain.\")"
      ],
      "metadata": {
        "id": "UXYGOXFWpjje",
        "outputId": "4c3bfe89-6cb7-4876-d68e-67c0c2a3aaaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Duplicate Comments] Removed 98,589 identical comment texts → 2,638,394 remain.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "required_listings_cols = [\"id\", \"price\", \"property_type\", \"room_type\", \"host_is_superhost\", \"neighbourhood\", \"region_name\", \"region_parent_name\", \"region_parent_parent_name\" ]\n",
        "\n",
        "missing_listings = [c for c in required_listings_cols if c not in listings.columns]\n",
        "\n",
        "print(\"Missing in listings:\", missing_listings)\n",
        "\n",
        "listings_df = listings[required_listings_cols].copy()\n",
        "\n",
        "print(\"Listings columns selected:\", list(listings_df.columns))\n",
        "\n",
        "print(f\"Final English-only reviews: {len(reviews_df_step2_comments):,}\")\n",
        "print(f\"Final listings: {len(listings_df):,}\")"
      ],
      "metadata": {
        "id": "DPIRTZvJuWoR",
        "outputId": "1b30f842-b9a3-4824-d654-f87578137814",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing in listings: []\n",
            "Listings columns selected: ['id', 'price', 'property_type', 'room_type', 'host_is_superhost', 'neighbourhood', 'region_name', 'region_parent_name', 'region_parent_parent_name']\n",
            "Final English-only reviews: 2,638,394\n",
            "Final listings: 46,645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATE FILTERING (Last 3 Years)\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Convert 'date' to datetime and remove invalid ones\n",
        "reviews_df_step2_comments[\"date\"] = pd.to_datetime(reviews_df_step2_comments[\"date\"], errors=\"coerce\")\n",
        "invalid_dates = reviews_df_step2_comments[\"date\"].isna().sum()\n",
        "reviews_df_step2_date = reviews_df_step2_comments.dropna(subset=[\"date\"]).copy()\n",
        "print(f\"[Invalid Dates] Removed {invalid_dates:,} rows with invalid date → {len(reviews_df_step2_date):,} remain.\")\n",
        "\n",
        "# Keep only reviews from the past 3 years up to today\n",
        "today = pd.Timestamp.today().normalize()\n",
        "three_years_ago = today - pd.DateOffset(years=3)\n",
        "\n",
        "out_of_range = (reviews_df_step2_date[\"date\"] < three_years_ago).sum()\n",
        "reviews_df_step2_date = reviews_df_step2_date.loc[reviews_df_step2_date[\"date\"] >= three_years_ago].copy()\n",
        "print(f\"[Date Filter] Removed {out_of_range:,} reviews older than {three_years_ago.date()} → {len(reviews_df_step2_date):,} remain.\")\n",
        "\n",
        "# sort by date (newest first)\n",
        "reviews_df_step2_date = reviews_df_step2_date.sort_values(\"date\", ascending=False).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "uwTZW7xqD0Vn",
        "outputId": "d7b2b69e-89a5-44d0-b891-dbf875383d1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Invalid Dates] Removed 0 rows with invalid date → 2,638,394 remain.\n",
            "[Date Filter] Removed 1,104,972 reviews older than 2022-10-17 → 1,533,422 remain.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Final Step 2 reviews: {len(reviews_df_step2_date):,}\")\n",
        "print(f\"Final listings: {len(listings_df):,}\")"
      ],
      "metadata": {
        "id": "rh_J_LM1GFbp",
        "outputId": "24e6acc0-8714-474f-9f1f-2aed76eebd2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Step 2 reviews: 1,533,422\n",
            "Final listings: 46,645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Step 3: TEXT NORMALIZATION\n",
        "# Lowercase, strip punctuation & digits, remove stopwords, lemmatize\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "try:\n",
        "    nltk.data.find(\"corpora/stopwords\")\n",
        "except LookupError:\n",
        "    nltk.download(\"stopwords\")\n",
        "try:\n",
        "    nltk.data.find(\"corpora/wordnet\")\n",
        "except LookupError:\n",
        "    nltk.download(\"wordnet\")\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "BoA8CkvRGFs5",
        "outputId": "7f2b45ae-883c-439c-ba44-d9f92b388cfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(text: str) -> str:\n",
        "    \"\"\"Lowercase → remove punctuation/digits → stopword removal → lemmatize.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    # 1) lowercase\n",
        "    text = text.lower()\n",
        "    # 2) keep letters and spaces only\n",
        "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
        "    # 3) tokenize (simple whitespace split)\n",
        "    tokens = text.split()\n",
        "    # 4) remove stopwords & short tokens\n",
        "    tokens = [t for t in tokens if t not in stop_words and len(t) > 2]\n",
        "    # 5) lemmatize\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    # 6) rejoin\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Apply normalization to the reviews\n",
        "assert {\"id\",\"listing_id\",\"date\",\"comments\"}.issubset(reviews_df_step2_date.columns), \\\n",
        "    \"reviews  must have id, listing_id, date, comments\"\n",
        "\n",
        "print(\"Normalizing review comments → reviews_df_step2_date['text']...\")\n",
        "reviews_df_step3 = reviews_df_step2_date.copy()\n",
        "reviews_df_step3[\"text\"] = reviews_df_step3[\"comments\"].apply(normalize_text)"
      ],
      "metadata": {
        "id": "P2LZ6_-9JH4k",
        "outputId": "56d47958-631f-4157-b498-d074b7e6c328",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalizing review comments → reviews_df_step2_date['text']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Final Step 3 reviews: {len(reviews_df_step3):,}\")"
      ],
      "metadata": {
        "id": "cRZ7MXa5JIFF",
        "outputId": "8448de4c-c0de-4df6-ee70-cbd06f595935",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Step 3 reviews: 1,533,422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: DATA INTEGRATION & STORAGE FORMAT\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Helpers\n",
        "def clean_price(x):\n",
        "    \"\"\"Strip currency symbols, commas, spaces; keep digits and decimal.\"\"\"\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    s = str(x)\n",
        "    s = re.sub(r\"[^\\d.,]\", \"\", s)        # remove currency and other chars\n",
        "    s = s.replace(\",\", \"\")               # drop thousands sep\n",
        "    return pd.to_numeric(s, errors=\"coerce\")\n",
        "\n",
        "def _norm_text(s):\n",
        "    if not isinstance(s, str):\n",
        "        return np.nan\n",
        "    s = re.sub(r\"\\s+\", \" \", s.strip())\n",
        "    # Title case but keep ALL-CAPS acronyms\n",
        "    return s.title()\n",
        "\n",
        "# Required listing columns\n",
        "sel_listing_cols = [\n",
        "    \"id\", \"price\", \"property_type\", \"room_type\", \"host_is_superhost\",\n",
        "    \"neighbourhood\", \"region_name\", \"region_parent_name\", \"region_parent_parent_name\"\n",
        "]\n",
        "missing_lst = [c for c in sel_listing_cols if c not in listings_df.columns]\n",
        "if missing_lst:\n",
        "    raise ValueError(f\"listings_df missing required columns: {missing_lst}\")\n",
        "\n",
        "listings_work = listings_df[sel_listing_cols].copy()\n",
        "\n",
        "# Normalize text-ish fields and clean price\n",
        "for c in [\"neighbourhood\", \"region_name\", \"region_parent_name\", \"region_parent_parent_name\"]:\n",
        "    listings_work[c] = listings_work[c].map(_norm_text)\n",
        "listings_work[\"price_num\"] = listings_work[\"price\"].map(clean_price)\n",
        "\n",
        "# Prefer region_parent_name (region), else region_name (city/area), else neighbourhood\n",
        "listings_work[\"region\"] = (\n",
        "    listings_work[\"region_parent_name\"]\n",
        "    .fillna(listings_work[\"region_name\"])\n",
        "    .fillna(listings_work[\"neighbourhood\"])\n",
        ")\n",
        "\n",
        "# Finalize listings schema\n",
        "listings_work = listings_work.rename(columns={\"id\": \"listing_id\"})[\n",
        "    [\"listing_id\", \"price_num\", \"property_type\", \"room_type\", \"host_is_superhost\",\n",
        "     \"neighbourhood\", \"region_name\", \"region_parent_name\", \"region_parent_parent_name\", \"region\"]\n",
        "].copy()\n",
        "\n",
        "# Keep minimal review schema + normalized text\n",
        "reviews_min = reviews_df_step3[[\"id\", \"listing_id\", \"date\", \"text\"]].copy()\n",
        "reviews_min = reviews_min.rename(columns={\"id\": \"review_id\"})\n",
        "\n",
        "# Merge\n",
        "merged = reviews_min.merge(listings_work, on=\"listing_id\", how=\"left\")\n",
        "\n",
        "# Types & ordering\n",
        "merged[\"review_id\"]  = merged[\"review_id\"].astype(str)\n",
        "merged[\"listing_id\"] = merged[\"listing_id\"].astype(str)\n",
        "merged[\"date\"] = pd.to_datetime(merged[\"date\"], errors=\"coerce\", utc=True).dt.tz_convert(None)\n",
        "merged = merged.dropna(subset=[\"date\"]).sort_values([\"listing_id\", \"date\"]).reset_index(drop=True)\n",
        "\n",
        "# Derive time keys\n",
        "merged[\"year\"]  = merged[\"date\"].dt.year.astype(\"int16\")\n",
        "merged[\"month\"] = merged[\"date\"].dt.month.astype(\"int8\")\n",
        "\n",
        "# Save to Parquet\n",
        "FINAL_PARQUET = \"data/airbnb_reviews_cleaned.parquet\"\n",
        "merged.to_parquet(FINAL_PARQUET, index=False, compression=\"snappy\")\n",
        "print(f\"[Saved] Analysis-ready Parquet → {FINAL_PARQUET}\")\n",
        "print(\"Final schema:\", list(merged.columns))\n",
        "print(merged.dtypes)"
      ],
      "metadata": {
        "id": "LPjh7Xk-KIZG",
        "outputId": "12c84d44-4e4e-4051-9d90-93e3549337ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Saved] Analysis-ready Parquet → data/airbnb_reviews_cleaned.parquet\n",
            "Final schema: ['review_id', 'listing_id', 'date', 'text', 'price_num', 'property_type', 'room_type', 'host_is_superhost', 'neighbourhood', 'region_name', 'region_parent_name', 'region_parent_parent_name', 'region', 'year', 'month']\n",
            "review_id                            object\n",
            "listing_id                           object\n",
            "date                         datetime64[ns]\n",
            "text                                 object\n",
            "price_num                           float64\n",
            "property_type                        object\n",
            "room_type                            object\n",
            "host_is_superhost                    object\n",
            "neighbourhood                        object\n",
            "region_name                          object\n",
            "region_parent_name                   object\n",
            "region_parent_parent_name           float64\n",
            "region                               object\n",
            "year                                  int16\n",
            "month                                  int8\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: OUTCOME OF PREPROCESSING\n",
        "# Summarize the final Airbnb dataset after full cleaning and integration.\n",
        "\n",
        "# basic structure\n",
        "n_reviews   = len(merged)\n",
        "n_listings  = merged[\"listing_id\"].nunique()\n",
        "n_regions   = merged[\"region\"].nunique(dropna=True)\n",
        "n_superhosts = merged[\"host_is_superhost\"].nunique()\n",
        "region_cov  = merged[\"region\"].notna().mean() * 100\n",
        "\n",
        "# Temporal coverage\n",
        "date_min = merged[\"date\"].min().date()\n",
        "date_max = merged[\"date\"].max().date()\n",
        "year_span = merged[\"year\"].nunique()\n",
        "\n",
        "# ]Listing-level attributes summary\n",
        "mean_price = merged[\"price_num\"].mean()\n",
        "median_price = merged[\"price_num\"].median()\n",
        "\n",
        "# Summary table\n",
        "summary = {\n",
        "    \"Total reviews (final)\": f\"{n_reviews:,}\",\n",
        "    \"Unique listings\": f\"{n_listings:,}\",\n",
        "    \"Distinct regions\": f\"{n_regions:,}\",\n",
        "    \"Region coverage (non-null)\": f\"{region_cov:.2f}%\",\n",
        "    \"Date range\": f\"{date_min} → {date_max}\",\n",
        "    \"Year span\": f\"{year_span} years\",\n",
        "    \"Mean price (NZD)\": f\"{mean_price:,.2f}\",\n",
        "    \"Median price (NZD)\": f\"{median_price:,.2f}\"\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(list(summary.items()), columns=[\"Metric\", \"Value\"])\n",
        "\n",
        "print(\"\\n=== OUTCOME OF PREPROCESSING ===\")\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "# Save summary table for appendix\n",
        "summary_path = \"figures/preprocessing_outcome_summary.csv\"\n",
        "summary_df.to_csv(summary_path, index=False, encoding=\"utf-8\")\n",
        "print(f\"\\n[Saved] Outcome summary → {summary_path}\")"
      ],
      "metadata": {
        "id": "BZHEnC0dKIk0",
        "outputId": "e534ca69-3b9f-4789-f690-f13a756db039",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== OUTCOME OF PREPROCESSING ===\n",
            "                    Metric                   Value\n",
            "     Total reviews (final)               1,533,422\n",
            "           Unique listings                  39,017\n",
            "          Distinct regions                      67\n",
            "Region coverage (non-null)                 100.00%\n",
            "                Date range 2022-10-17 → 2025-08-06\n",
            "                 Year span                 4 years\n",
            "          Mean price (NZD)                  205.51\n",
            "        Median price (NZD)                  150.00\n",
            "\n",
            "[Saved] Outcome summary → figures/preprocessing_outcome_summary.csv\n"
          ]
        }
      ]
    }
  ]
}
