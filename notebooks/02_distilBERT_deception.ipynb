{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nantmoe-theingi/airbnb-nz-deception-sentiment/blob/main/notebooks/02_distilBERT_deception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O1Os6RxJ_qO",
        "outputId": "0f7ee71a-e584-4ff2-b7dc-6cf1f9bf228d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer, set_seed\n",
        ")\n",
        "\n",
        "set_seed(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_1hWtMtJ_qS",
        "outputId": "70a5df4f-5472-461a-a266-6214529a78d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 1276 | Val: 160 | Test: 160\n"
          ]
        }
      ],
      "source": [
        "# Load and Split Dataset\n",
        "df = pd.read_csv(\"data/deception_opinion_cleaned.csv\")\n",
        "df = df.dropna(subset=[\"text\", \"label\"])\n",
        "df[\"label\"] = df[\"label\"].astype(int)\n",
        "\n",
        "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"label\"], random_state=42)\n",
        "\n",
        "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfjA8ysDJ_qS",
        "outputId": "efacf41d-8ac9-4dc8-bbfa-bed66a0474ec",
        "colab": {
          "referenced_widgets": [
            "21d40773f3514707a773a94ee83b03fa",
            "d351e5358f1f4be9bcd39a20c689690c",
            "14687e08f7254673898acccaf295883d"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21d40773f3514707a773a94ee83b03fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1276 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d351e5358f1f4be9bcd39a20c689690c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14687e08f7254673898acccaf295883d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ===== DistilBERT sweep (simple & reliable) =====\n",
        "import itertools, numpy as np, pandas as pd, torch, joblib\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    Trainer, TrainingArguments, set_seed\n",
        ")\n",
        "\n",
        "# -------------------\n",
        "# 0) Config & seeding\n",
        "# -------------------\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "ROOT_DIR = Path(\"artifacts/distilbert_deception_sweep\")\n",
        "ROOT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "set_seed(42)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# -------------------\n",
        "# 1) Tokenizer & metric\n",
        "# -------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df).map(tokenize, batched=True)\n",
        "val_ds   = Dataset.from_pandas(val_df).map(tokenize, batched=True)\n",
        "test_ds  = Dataset.from_pandas(test_df).map(tokenize, batched=True)\n",
        "\n",
        "train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "val_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    return {\n",
        "        \"accuracy\":  accuracy_score(labels, preds),\n",
        "        \"precision\": precision_score(labels, preds, pos_label=1),\n",
        "        \"recall\":    recall_score(labels, preds, pos_label=1),\n",
        "        \"f1\":        f1_score(labels, preds, pos_label=1),\n",
        "    }\n",
        "\n",
        "def new_model():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmrykZXRJ_qT"
      },
      "outputs": [],
      "source": [
        "# -------------------\n",
        "# 2) Sweep space (kept small but meaningful)\n",
        "# -------------------\n",
        "grid = {\n",
        "    \"num_train_epochs\": [2, 3, 4],\n",
        "    \"learning_rate\": [1e-5, 2e-5, 3e-5],\n",
        "    \"lr_scheduler_type\": [\"linear\", \"cosine\"],\n",
        "    \"warmup_ratio\": [0.0, 0.06],\n",
        "}\n",
        "\n",
        "results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyEfy1NIJ_qT",
        "outputId": "ae07430c-f146-4ecf-a179-aa5f5dc0fd82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deterministic mode OFF and can train now.\n"
          ]
        }
      ],
      "source": [
        "# Reset deterministic mode in the current kernel (no restart needed)\n",
        "import os, torch\n",
        "\n",
        "# turn off strict determinism\n",
        "torch.use_deterministic_algorithms(False)\n",
        "\n",
        "# use safe, reproducible-enough defaults\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = False\n",
        "\n",
        "# allow TF32 again (optional; keeps things simple)\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "# remove cuBLAS workspace setting so cuBLAS won't complain\n",
        "os.environ.pop(\"CUBLAS_WORKSPACE_CONFIG\", None)\n",
        "\n",
        "print(\"Deterministic mode OFF and can train now.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzivMnHgJ_qU",
        "outputId": "7029b72e-453d-4938-d030-36d0b608cd11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [320/320 00:50, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.597700</td>\n",
              "      <td>0.418103</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.784091</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.821429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.322600</td>\n",
              "      <td>0.425615</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.747475</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.826816</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [320/320 00:40, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.601000</td>\n",
              "      <td>0.384153</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.853659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.293700</td>\n",
              "      <td>0.387483</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.776596</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.839080</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [320/320 00:41, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.577800</td>\n",
              "      <td>0.364934</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.867470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.288800</td>\n",
              "      <td>0.344524</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [320/320 00:38, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.593800</td>\n",
              "      <td>0.372173</td>\n",
              "      <td>0.868750</td>\n",
              "      <td>0.839080</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.874251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.288600</td>\n",
              "      <td>0.352538</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.793478</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.848837</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [320/320 00:36, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.512200</td>\n",
              "      <td>0.308356</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.865854</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.876543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.214700</td>\n",
              "      <td>0.372225</td>\n",
              "      <td>0.856250</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.865497</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [320/320 00:44, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.527200</td>\n",
              "      <td>0.316954</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.848837</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.879518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.211500</td>\n",
              "      <td>0.345218</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.882353</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [320/320 00:36, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.507000</td>\n",
              "      <td>0.300990</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.878049</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.216400</td>\n",
              "      <td>0.310399</td>\n",
              "      <td>0.881250</td>\n",
              "      <td>0.867470</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.883436</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [320/320 00:44, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.530600</td>\n",
              "      <td>0.303204</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.848837</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.879518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.222800</td>\n",
              "      <td>0.293660</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.869048</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.890244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [320/320 00:30, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.498900</td>\n",
              "      <td>0.281661</td>\n",
              "      <td>0.868750</td>\n",
              "      <td>0.893333</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.864516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.199000</td>\n",
              "      <td>0.407715</td>\n",
              "      <td>0.856250</td>\n",
              "      <td>0.820225</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.863905</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [320/320 00:32, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.522600</td>\n",
              "      <td>0.291415</td>\n",
              "      <td>0.881250</td>\n",
              "      <td>0.917808</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.875817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.200500</td>\n",
              "      <td>0.382019</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.882353</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [320/320 00:42, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.498500</td>\n",
              "      <td>0.267349</td>\n",
              "      <td>0.881250</td>\n",
              "      <td>0.896104</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.878981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.193600</td>\n",
              "      <td>0.357846</td>\n",
              "      <td>0.868750</td>\n",
              "      <td>0.839080</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.874251</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [320/320 00:42, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.529600</td>\n",
              "      <td>0.290389</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.894737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.216300</td>\n",
              "      <td>0.348427</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.848837</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.879518</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 01:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.581700</td>\n",
              "      <td>0.364008</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.829545</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.869048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.265800</td>\n",
              "      <td>0.387502</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.775510</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.853933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.236200</td>\n",
              "      <td>0.345383</td>\n",
              "      <td>0.868750</td>\n",
              "      <td>0.831461</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.875740</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 00:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.632000</td>\n",
              "      <td>0.378901</td>\n",
              "      <td>0.831250</td>\n",
              "      <td>0.835443</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.830189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.277000</td>\n",
              "      <td>0.441102</td>\n",
              "      <td>0.831250</td>\n",
              "      <td>0.762376</td>\n",
              "      <td>0.962500</td>\n",
              "      <td>0.850829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.240800</td>\n",
              "      <td>0.364501</td>\n",
              "      <td>0.868750</td>\n",
              "      <td>0.817204</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.878613</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 00:57, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.605700</td>\n",
              "      <td>0.349682</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.845238</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.865854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.266400</td>\n",
              "      <td>0.405537</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.962500</td>\n",
              "      <td>0.860335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.230700</td>\n",
              "      <td>0.371848</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.860465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 01:07, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.627700</td>\n",
              "      <td>0.369249</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.831325</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.846626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.268900</td>\n",
              "      <td>0.432696</td>\n",
              "      <td>0.831250</td>\n",
              "      <td>0.762376</td>\n",
              "      <td>0.962500</td>\n",
              "      <td>0.850829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.235000</td>\n",
              "      <td>0.373362</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.808511</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.873563</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 00:58, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.515600</td>\n",
              "      <td>0.304049</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.231800</td>\n",
              "      <td>0.409014</td>\n",
              "      <td>0.868750</td>\n",
              "      <td>0.810526</td>\n",
              "      <td>0.962500</td>\n",
              "      <td>0.880000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.160600</td>\n",
              "      <td>0.383020</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.882353</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 00:59, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.554300</td>\n",
              "      <td>0.323392</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.862500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.255200</td>\n",
              "      <td>0.468113</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>0.962500</td>\n",
              "      <td>0.855556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.176200</td>\n",
              "      <td>0.396487</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.883721</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 01:04, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.510700</td>\n",
              "      <td>0.307709</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.868421</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.846154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.225100</td>\n",
              "      <td>0.376432</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.815217</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.872093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.144300</td>\n",
              "      <td>0.387448</td>\n",
              "      <td>0.868750</td>\n",
              "      <td>0.824176</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.877193</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 01:04, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.552900</td>\n",
              "      <td>0.321951</td>\n",
              "      <td>0.868750</td>\n",
              "      <td>0.855422</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.871166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.252900</td>\n",
              "      <td>0.398403</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.962500</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.169500</td>\n",
              "      <td>0.377373</td>\n",
              "      <td>0.868750</td>\n",
              "      <td>0.817204</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.878613</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 00:53, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.490500</td>\n",
              "      <td>0.335459</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.229400</td>\n",
              "      <td>0.416388</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.852273</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.892857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.124100</td>\n",
              "      <td>0.428530</td>\n",
              "      <td>0.893750</td>\n",
              "      <td>0.870588</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.896970</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 00:53, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.541800</td>\n",
              "      <td>0.346500</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.842105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.224100</td>\n",
              "      <td>0.412182</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.797872</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.862069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.123900</td>\n",
              "      <td>0.431161</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.869048</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.890244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 00:58, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.490400</td>\n",
              "      <td>0.367208</td>\n",
              "      <td>0.831250</td>\n",
              "      <td>0.934426</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.808511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.217800</td>\n",
              "      <td>0.417379</td>\n",
              "      <td>0.881250</td>\n",
              "      <td>0.842697</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.887574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.128700</td>\n",
              "      <td>0.433399</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.882353</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 00:55, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.546500</td>\n",
              "      <td>0.370726</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.921875</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>0.819444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.220800</td>\n",
              "      <td>0.446889</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.795699</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.855491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.124100</td>\n",
              "      <td>0.444512</td>\n",
              "      <td>0.868750</td>\n",
              "      <td>0.847059</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.872727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [640/640 01:25, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.612700</td>\n",
              "      <td>0.356757</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.840764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.273000</td>\n",
              "      <td>0.412551</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.962500</td>\n",
              "      <td>0.860335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.225800</td>\n",
              "      <td>0.366369</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.822222</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.870588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.156900</td>\n",
              "      <td>0.410200</td>\n",
              "      <td>0.868750</td>\n",
              "      <td>0.824176</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.877193</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [640/640 01:20, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.645300</td>\n",
              "      <td>0.381951</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.808989</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.852071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.275000</td>\n",
              "      <td>0.415752</td>\n",
              "      <td>0.831250</td>\n",
              "      <td>0.773196</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.847458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.236600</td>\n",
              "      <td>0.383260</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.822222</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.870588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.161800</td>\n",
              "      <td>0.408552</td>\n",
              "      <td>0.868750</td>\n",
              "      <td>0.831461</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.875740</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [640/640 01:40, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.609000</td>\n",
              "      <td>0.353767</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.867470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.257400</td>\n",
              "      <td>0.423220</td>\n",
              "      <td>0.831250</td>\n",
              "      <td>0.773196</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.847458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.223000</td>\n",
              "      <td>0.402508</td>\n",
              "      <td>0.868750</td>\n",
              "      <td>0.824176</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.877193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.151800</td>\n",
              "      <td>0.415786</td>\n",
              "      <td>0.868750</td>\n",
              "      <td>0.824176</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.877193</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [640/640 01:35, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.641900</td>\n",
              "      <td>0.379221</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.802198</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.853801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.267800</td>\n",
              "      <td>0.430953</td>\n",
              "      <td>0.831250</td>\n",
              "      <td>0.773196</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.847458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.228900</td>\n",
              "      <td>0.403703</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.815217</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.872093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.154700</td>\n",
              "      <td>0.417358</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.815217</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.872093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [640/640 01:26, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.537300</td>\n",
              "      <td>0.311201</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.921053</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.897436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.229900</td>\n",
              "      <td>0.467344</td>\n",
              "      <td>0.831250</td>\n",
              "      <td>0.762376</td>\n",
              "      <td>0.962500</td>\n",
              "      <td>0.850829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.145400</td>\n",
              "      <td>0.352071</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.902439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.081700</td>\n",
              "      <td>0.396422</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.872093</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.903614</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [640/640 01:38, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.573600</td>\n",
              "      <td>0.320863</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.868421</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.846154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.256000</td>\n",
              "      <td>0.473669</td>\n",
              "      <td>0.831250</td>\n",
              "      <td>0.757282</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>0.852459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.173100</td>\n",
              "      <td>0.334284</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.890244</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.901235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.079400</td>\n",
              "      <td>0.403093</td>\n",
              "      <td>0.893750</td>\n",
              "      <td>0.862069</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.898204</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [640/640 01:28, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.537400</td>\n",
              "      <td>0.326594</td>\n",
              "      <td>0.881250</td>\n",
              "      <td>0.955224</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.870748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.241200</td>\n",
              "      <td>0.388239</td>\n",
              "      <td>0.856250</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.865497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.133900</td>\n",
              "      <td>0.398762</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.890244</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.901235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.070300</td>\n",
              "      <td>0.430105</td>\n",
              "      <td>0.893750</td>\n",
              "      <td>0.870588</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.896970</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [640/640 01:35, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.572000</td>\n",
              "      <td>0.313036</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.881579</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.858974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.259700</td>\n",
              "      <td>0.425762</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.775510</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.853933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.161500</td>\n",
              "      <td>0.351838</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.890244</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.901235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.069600</td>\n",
              "      <td>0.383197</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.852273</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.892857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [640/640 01:14, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.521200</td>\n",
              "      <td>0.297172</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.871795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.232600</td>\n",
              "      <td>0.369503</td>\n",
              "      <td>0.881250</td>\n",
              "      <td>0.867470</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.883436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.124800</td>\n",
              "      <td>0.445710</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.060100</td>\n",
              "      <td>0.503976</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.890244</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.901235</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [640/640 01:17, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.538300</td>\n",
              "      <td>0.263458</td>\n",
              "      <td>0.893750</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.894410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.239800</td>\n",
              "      <td>0.334373</td>\n",
              "      <td>0.893750</td>\n",
              "      <td>0.879518</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.895706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.128900</td>\n",
              "      <td>0.380855</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>0.891566</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.907975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.039200</td>\n",
              "      <td>0.431234</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>0.891566</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.907975</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [640/640 01:26, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.525300</td>\n",
              "      <td>0.327171</td>\n",
              "      <td>0.887500</td>\n",
              "      <td>0.918919</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.883117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.228700</td>\n",
              "      <td>0.363335</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.840909</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.880952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.116200</td>\n",
              "      <td>0.440739</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.043000</td>\n",
              "      <td>0.457990</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2724274408.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [640/640 01:34, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.554500</td>\n",
              "      <td>0.304737</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.842105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.243400</td>\n",
              "      <td>0.328440</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.890244</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.901235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.124500</td>\n",
              "      <td>0.397815</td>\n",
              "      <td>0.912500</td>\n",
              "      <td>0.902439</td>\n",
              "      <td>0.925000</td>\n",
              "      <td>0.913580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.028500</td>\n",
              "      <td>0.425507</td>\n",
              "      <td>0.918750</td>\n",
              "      <td>0.894118</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.921212</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# -------------------\n",
        "# 3) Run sweep\n",
        "# -------------------\n",
        "for epochs, lr, sched, warm in itertools.product(\n",
        "    grid[\"num_train_epochs\"], grid[\"learning_rate\"],\n",
        "    grid[\"lr_scheduler_type\"], grid[\"warmup_ratio\"]\n",
        "):\n",
        "    run_name = f\"e{epochs}_lr{lr}_sch-{sched}_warm{warm}\"\n",
        "    output_dir = ROOT_DIR / \"runs\" / run_name\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    model = new_model()\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=str(output_dir),\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        learning_rate=lr,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=0.01,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        greater_is_better=True,\n",
        "        lr_scheduler_type=sched,\n",
        "        warmup_ratio=warm,\n",
        "        logging_steps=100,\n",
        "        save_total_limit=1,   # keep it tidy\n",
        "        report_to=[],         # no wandb/etc\n",
        "        seed=42,\n",
        "        fp16=False,           # keep simple; avoids cuBLAS determinism issues\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds,\n",
        "        eval_dataset=val_ds,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    val_metrics = trainer.evaluate()\n",
        "    results.append({\n",
        "        \"run\": run_name, \"epochs\": epochs, \"lr\": lr,\n",
        "        \"scheduler\": sched, \"warmup\": warm,\n",
        "        **{k: round(val_metrics[k], 4) for k in\n",
        "           (\"eval_accuracy\", \"eval_precision\", \"eval_recall\", \"eval_f1\")}\n",
        "    })\n",
        "\n",
        "    # free memory between runs\n",
        "    del trainer, model\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxBSU-o1J_qU",
        "outputId": "7fb9f810-9a70-4d9b-cd0a-051bf1d57fe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top candidates:\n",
            "                                run  epochs       lr scheduler  warmup  \\\n",
            "35  e4_lr3e-05_sch-cosine_warm0.06       4  0.00003    cosine    0.06   \n",
            "33  e4_lr3e-05_sch-linear_warm0.06       4  0.00003    linear    0.06   \n",
            "28   e4_lr2e-05_sch-linear_warm0.0       4  0.00002    linear    0.00   \n",
            "29  e4_lr2e-05_sch-linear_warm0.06       4  0.00002    linear    0.06   \n",
            "32   e4_lr3e-05_sch-linear_warm0.0       4  0.00003    linear    0.00   \n",
            "\n",
            "    Accuracy  Precision  Recall      F1  \n",
            "35    0.9187     0.8941  0.9500  0.9212  \n",
            "33    0.9062     0.8916  0.9250  0.9080  \n",
            "28    0.9000     0.8721  0.9375  0.9036  \n",
            "29    0.9000     0.8902  0.9125  0.9012  \n",
            "32    0.9000     0.8902  0.9125  0.9012  \n",
            "\n",
            "Best config: {'run': 'e4_lr3e-05_sch-cosine_warm0.06', 'epochs': 4, 'lr': 3e-05, 'scheduler': 'cosine', 'warmup': 0.06, 'Accuracy': 0.9187, 'Precision': 0.8941, 'Recall': 0.95, 'F1': 0.9212}\n"
          ]
        }
      ],
      "source": [
        "# -------------------\n",
        "# 4) Pick best by F1\n",
        "# -------------------\n",
        "df = pd.DataFrame(results).rename(columns={\n",
        "    \"eval_accuracy\": \"Accuracy\",\n",
        "    \"eval_precision\": \"Precision\",\n",
        "    \"eval_recall\": \"Recall\",\n",
        "    \"eval_f1\": \"F1\"\n",
        "}).sort_values(\"F1\", ascending=False)\n",
        "\n",
        "print(\"Top candidates:\\n\", df.head(5))\n",
        "df.to_csv(ROOT_DIR / \"sweep_results.csv\", index=False)\n",
        "\n",
        "best = df.iloc[0]\n",
        "print(\"\\nBest config:\", best.to_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIh0tB1bJ_qV",
        "outputId": "09309786-b5aa-4d2a-9117-a8bf47dd2c97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2996161753.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [640/640 01:36, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.291708</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.878049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.400993</td>\n",
              "      <td>0.881250</td>\n",
              "      <td>0.842697</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.887574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.482223</td>\n",
              "      <td>0.881250</td>\n",
              "      <td>0.886076</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.880503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.274400</td>\n",
              "      <td>0.482832</td>\n",
              "      <td>0.893750</td>\n",
              "      <td>0.862069</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.898204</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation (best run): {'eval_loss': 0.48283225297927856, 'eval_accuracy': 0.89375, 'eval_precision': 0.8620689655172413, 'eval_recall': 0.9375, 'eval_f1': 0.8982035928143712, 'eval_runtime': 0.6879, 'eval_samples_per_second': 232.581, 'eval_steps_per_second': 29.073, 'epoch': 4.0}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -------------------\n",
        "# 5) Retrain once with best config\n",
        "# -------------------\n",
        "FINAL_DIR = ROOT_DIR / \"best_model\"\n",
        "FINAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "model = new_model()\n",
        "best_args = TrainingArguments(\n",
        "    output_dir=str(FINAL_DIR),\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    learning_rate=float(best[\"lr\"]),\n",
        "    num_train_epochs=int(best[\"epochs\"]),\n",
        "    lr_scheduler_type=best[\"scheduler\"],\n",
        "    warmup_ratio=float(best[\"warmup\"]),\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    report_to=[],\n",
        "    seed=42,\n",
        "    fp16=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=best_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "print(\"\\nValidation (best run):\", trainer.evaluate())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqcRo0CYJ_qV",
        "outputId": "e9207308-248b-422a-ec0f-19ea7b31c0e4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='40' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test metrics: {'eval_loss': 0.5304847955703735, 'eval_accuracy': 0.88125, 'eval_precision': 0.8279569892473119, 'eval_recall': 0.9625, 'eval_f1': 0.8901734104046243, 'eval_runtime': 0.4652, 'eval_samples_per_second': 343.956, 'eval_steps_per_second': 42.994, 'epoch': 4.0}\n"
          ]
        }
      ],
      "source": [
        "# 6) Final test evaluation\n",
        "# -------------------\n",
        "test_metrics = trainer.evaluate(test_ds)\n",
        "print(\"\\nTest metrics:\", test_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKubmVaVJ_qV",
        "outputId": "09827937-2d65-43b0-a4aa-cefcd12825a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved model, tokenizer, & label map to: /content/drive/MyDrive/Colab Notebooks/airbnb_nz_deception_sentiment/artifacts/distilbert_deception_sweep/best_model\n"
          ]
        }
      ],
      "source": [
        "# 7) Save artifacts\n",
        "# -------------------\n",
        "trainer.save_model(FINAL_DIR)              # model + config\n",
        "tokenizer.save_pretrained(FINAL_DIR)       # tokenizer files\n",
        "joblib.dump({\"truthful\": 0, \"deceptive\": 1}, FINAL_DIR / \"label_map.joblib\") # artifacts/distilbert_deception_sweep/best_model\n",
        "print(\"\\nSaved model, tokenizer, & label map to:\", FINAL_DIR.resolve())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmCAZt9cJ_qV",
        "outputId": "25f2efc2-c8c1-489d-926c-6d49291c8893"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get predictions and labels\n",
        "preds_output = trainer.predict(test_ds)\n",
        "y_pred = np.argmax(preds_output.predictions, axis=1)\n",
        "y_true = preds_output.label_ids\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Truthful\", \"Deceptive\"])\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(cm, interpolation=\"nearest\", cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix (Test) — Deception DistillBERT\", fontsize=13)\n",
        "plt.xticks([0, 1], [\"truthful\", \"deceptive\"])\n",
        "plt.yticks([0, 1], [\"truthful\", \"deceptive\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "\n",
        "for (i, j), v in np.ndenumerate(cm):\n",
        "    color = \"white\" if v > cm.max() / 2 else \"black\"\n",
        "    plt.text(j, i, str(v), ha=\"center\", va=\"center\", color=color, fontsize=13)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG1ZB7s9J_qW",
        "outputId": "98eaf9cf-08cd-43f7-945a-12eb9d6f05bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added DistilBERT results to model_comparison_deception.csv\n",
            "                           Model  Accuracy    F1  Precision  Recall\n",
            "0                   SVM (TF–IDF)      0.87  0.87       0.85    0.90\n",
            "1  DistilBERT (Fine-tuned, test)      0.88  0.89       0.83    0.96\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "# Compute metrics from test predictions\n",
        "row_test = {\n",
        "    \"Model\": \"DistilBERT (Fine-tuned, test)\",\n",
        "    \"Accuracy\": round(accuracy_score(y_true, y_pred), 2),\n",
        "    \"F1\": round(f1_score(y_true, y_pred), 2),\n",
        "    \"Precision\": round(precision_score(y_true, y_pred), 2),\n",
        "    \"Recall\": round(recall_score(y_true, y_pred), 2),\n",
        "}\n",
        "\n",
        "# Create dataframe or append to file\n",
        "try:\n",
        "    df_test = pd.read_csv(\"figures/model_comparison_deception.csv\")\n",
        "except FileNotFoundError:\n",
        "    df_test = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"F1\", \"Precision\", \"Recall\"])\n",
        "\n",
        "df_test = pd.concat([df_test, pd.DataFrame([row_test])], ignore_index=True)\n",
        "\n",
        "# Save updated comparison table\n",
        "df_test.to_csv(\"figures/model_comparison_deception.csv\", index=False)\n",
        "print(\"Added DistilBERT results to model_comparison_deception.csv\")\n",
        "print(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BZbd-FIcJ_qW"
      },
      "outputs": [],
      "source": [
        "import torch, joblib\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# -----------------------------\n",
        "# Load model, tokenizer, and label map\n",
        "# -----------------------------\n",
        "def load_inference_components(artifacts_dir=\"artifacts/distilbert_deception_sweep/best_model\"):\n",
        "    artifacts_dir = Path(artifacts_dir)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(artifacts_dir)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(artifacts_dir)\n",
        "    label_map = joblib.load(artifacts_dir / \"label_map.joblib\")\n",
        "    inverse_label_map = {v: k for k, v in label_map.items()}\n",
        "    return model, tokenizer, inverse_label_map\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Inference function\n",
        "# -----------------------------\n",
        "def predict_deception(texts, model, tokenizer, label_map):\n",
        "    \"\"\"\n",
        "    Predict deception probabilities for given text(s).\n",
        "    Inputs:\n",
        "        texts: str or list of str\n",
        "        model, tokenizer, label_map: loaded components\n",
        "    Returns:\n",
        "        DataFrame with columns: text, predicted_label, confidence\n",
        "    \"\"\"\n",
        "    if isinstance(texts, str):\n",
        "        texts = [texts]\n",
        "\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Tokenize\n",
        "    encodings = tokenizer(\n",
        "        texts, padding=True, truncation=True, max_length=256, return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    # Inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encodings)\n",
        "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1).cpu().numpy()\n",
        "        confs = probs.max(dim=1).values.cpu().numpy()\n",
        "\n",
        "    # Map to labels\n",
        "    labels = [label_map[p] for p in preds]\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        \"text\": texts,\n",
        "        \"predicted_label\": labels,\n",
        "        \"confidence\": np.round(confs, 3)\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XLZFwj2J_qX",
        "outputId": "1c3a55b5-024b-43b5-cc5b-bf2556935f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text predicted_label  \\\n",
            "0  The host was friendly and the apartment was sp...       deceptive   \n",
            "1  This listing was fake, and the pictures were c...       deceptive   \n",
            "\n",
            "   confidence  \n",
            "0       0.959  \n",
            "1       0.744  \n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# Example usage\n",
        "# -----------------------------\n",
        "# Load everything once\n",
        "model, tokenizer, label_map = load_inference_components(\"artifacts/distilbert_deception_sweep/best_model\")\n",
        "\n",
        "# Predict one or multiple reviews\n",
        "texts = [\n",
        "    \"The host was friendly and the apartment was spotless!\",\n",
        "    \"This listing was fake, and the pictures were completely different.\"\n",
        "]\n",
        "\n",
        "results = predict_deception(texts, model, tokenizer, label_map)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xub-vhSWJ_qX",
        "outputId": "f8141c75-410c-4ebf-f95d-25bc4c4bc3db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text predicted_label  \\\n",
            "0  The room was spotless and the staff were incre...       deceptive   \n",
            "1  Best hotel ever! The photos are fake but you s...       deceptive   \n",
            "2  We waited two hours for check-in, and the mana...        truthful   \n",
            "\n",
            "   confidence  \n",
            "0       0.983  \n",
            "1       0.987  \n",
            "2       0.930  \n"
          ]
        }
      ],
      "source": [
        "texts = [\n",
        "    \"The room was spotless and the staff were incredibly friendly.\",\n",
        "    \"Best hotel ever! The photos are fake but you should totally stay here!\",\n",
        "    \"We waited two hours for check-in, and the manager kept making excuses.\"\n",
        "]\n",
        "\n",
        "results = predict_deception(texts, model, tokenizer, label_map)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "artifacts_dir = \"artifacts/distilbert_deception_sweep/best_model\"\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(artifacts_dir)\n",
        "tokenizer = AutoTokenizer.from_pretrained(artifacts_dir)\n",
        "\n",
        "\n",
        "# Load and Split Dataset\n",
        "df = pd.read_csv(\"data/deception_opinion_cleaned.csv\")\n",
        "df = df.dropna(subset=[\"text\", \"label\"])\n",
        "df[\"label\"] = df[\"label\"].astype(int)\n",
        "df[\"text\"] = df[\"text\"].astype(str)\n",
        "\n",
        "\n",
        "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"label\"], random_state=42)\n",
        "\n",
        "X_val = val_df[\"text\"].astype(str).tolist()\n",
        "y_val = val_df[\"label\"].astype(int).tolist()\n",
        "\n",
        "encodings_val = tokenizer(\n",
        "    X_val,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=256,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "val_dataset = Dataset.from_dict({\n",
        "    \"input_ids\": encodings_val[\"input_ids\"],\n",
        "    \"attention_mask\": encodings_val[\"attention_mask\"],\n",
        "    \"labels\": y_val\n",
        "})\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./tmp_eval\",\n",
        "    per_device_eval_batch_size=32,\n",
        "    dataloader_drop_last=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args\n",
        ")\n",
        "\n",
        "preds_output = trainer.predict(val_dataset)\n",
        "\n",
        "# Raw logits → probabilities\n",
        "logits = preds_output.predictions\n",
        "probs = torch.nn.functional.softmax(torch.tensor(logits), dim=1).numpy()\n",
        "\n",
        "# Probability of the \"deceptive\" class (index 1)\n",
        "y_val_prob = probs[:, 1]\n",
        "y_val_true = np.array(y_val)\n",
        "\n",
        "prec, rec, thresh = precision_recall_curve(y_val_true, y_val_prob)\n",
        "f1 = 2 * (prec * rec) / (prec + rec + 1e-9)\n",
        "best_idx = np.argmax(f1)\n",
        "best_thresh = thresh[best_idx]\n",
        "best_f1 = f1[best_idx]\n",
        "\n",
        "print(f\"Optimal threshold (τ) = {best_thresh:.2f}\")\n",
        "print(f\"Validation F1 = {best_f1:.3f}\")\n",
        "\n",
        "# Optional visualization\n",
        "os.makedirs(\"Figures\", exist_ok=True)\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(thresh, f1[:-1], linewidth=2)\n",
        "plt.axvline(best_thresh, color=\"red\", linestyle=\"--\", label=f\"τ={best_thresh:.2f}\")\n",
        "plt.xlabel(\"Threshold (τ)\")\n",
        "plt.ylabel(\"F1-score\")\n",
        "plt.title(\"Threshold Optimization on Validation Set\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figures/deception_threshold_curve.png\", dpi=300)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "wxEvBSBz-76U",
        "outputId": "050bca83-63f8-4921-ec34-e6c9f4ac3114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal threshold (τ) = 0.81\n",
            "Validation F1 = 0.908\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}